{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/jpmg86/anaconda3/envs/MuMRVQ/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.dataloading import *\n",
    "\n",
    "dataset = CustomAudioDataset(data_dir= \"/import/research_c4dm/JulienMarcoChrisRMRI/MTAT_wav\", target_length=5, n_augmentations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 120000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['wav'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def get_positive_mask(batch_size, seq_length):\n",
    "        # Create a mask where positives are indicated by consecutive elements in each batch\n",
    "        pos_mask = torch.zeros(batch_size, seq_length, dtype=torch.bool)\n",
    "        for i in range(batch_size):\n",
    "            start_idx = i * seq_length\n",
    "            end_idx = (i + 1) * seq_length\n",
    "            pos_mask[i, start_idx:end_idx] = True\n",
    "\n",
    "        # Extend the positive window for local tokens\n",
    "        # for i in range(seq_length):\n",
    "        #     start_pos = max(0, i - 3 // 2)\n",
    "        #     end_pos = min(seq_length, i + 3 // 2 + 1)\n",
    "        #     pos_mask[i, start_pos:end_pos] = True\n",
    "\n",
    "        return pos_mask\n",
    "    \n",
    "print(get_positive_mask(8,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 0.],\n",
      "        [0., 0., 0., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 0., 1.]])\n",
      "torch.Size([6, 512])\n",
      "torch.Size([6, 6])\n",
      "torch.Size([6, 6])\n",
      "tensor([[0., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 0., 1.],\n",
      "        [1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.]])\n",
      "torch.Size([6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.6094)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SupConLoss(nn.Module):\n",
    "    \"\"\"Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\"\"\"\n",
    "    def __init__(self, temperature=0.07, contrast_mode='all',\n",
    "                 base_temperature=0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels=None, mask=None):\n",
    "        \"\"\"Compute loss for model. If both `labels` and `mask` are None,\n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, ...].\n",
    "            labels: ground truth of shape [bsz].\n",
    "            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n",
    "                has the same class as sample i. Can be asymmetric.\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = (torch.device('cuda')\n",
    "                  if features.is_cuda\n",
    "                  else torch.device('cpu'))\n",
    "\n",
    "        if len(features.shape) < 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n",
    "                             'at least 3 dimensions are required')\n",
    "        if len(features.shape) > 3:\n",
    "            features = features.view(features.shape[0], features.shape[1], -1)\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        if labels is not None and mask is not None:\n",
    "            raise ValueError('Cannot define both `labels` and `mask`')\n",
    "        elif labels is None and mask is None:\n",
    "            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n",
    "        elif labels is not None:\n",
    "            labels = labels.contiguous().view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError('Num of labels does not match num of features')\n",
    "            mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        else:\n",
    "            mask = mask.float().to(device)\n",
    "\n",
    "        print(mask)\n",
    "\n",
    "        contrast_count = features.shape[1]\n",
    "        \n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        print(contrast_feature.shape)\n",
    "        if self.contrast_mode == 'one':\n",
    "            anchor_feature = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            anchor_feature = contrast_feature\n",
    "            anchor_count = contrast_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # compute logits\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature)\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "        \n",
    "        print(logits.shape)\n",
    "\n",
    "        # tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count) ## what is this mask?\n",
    "        print(mask.shape)\n",
    "        # mask-out self-contrast cases\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "            0\n",
    "        ) ## is this only self-contrast?\n",
    "        \n",
    "        mask = mask * logits_mask\n",
    "        \n",
    "        print(mask)\n",
    "\n",
    "        # compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "        \n",
    "        print(log_prob.shape)\n",
    "\n",
    "        # compute mean of log-likelihood over positive\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
    "\n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        # loss = loss.view(anchor_count, batch_size)\n",
    "\n",
    "        return loss.mean()\n",
    "    \n",
    "    \n",
    "loss = SupConLoss()\n",
    "test_data = torch.zeros((6,1,512))\n",
    "test_mask = torch.zeros(3,3)\n",
    "test_mask[0,1] = 1\n",
    "test_mask[1,0] = 1\n",
    "test_mask[1,1] = 1\n",
    "\n",
    "test_labels = torch.Tensor([1,1,1,2,2,1])\n",
    "loss(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 12000])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.split(torch.zeros((1,12000)),12000)).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# def get_contrastive_matrix(batch_size, sequence_length, num_augmentations, window_size):\n",
    "#     total_samples = batch_size* sequence_length * num_augmentations\n",
    "#     same_sample = torch.zeros((total_samples, total_samples), dtype=torch.int)\n",
    "#     window_mask = torch.zeros_like(same_sample)\n",
    "    \n",
    "#     window_width = window_size//2 +1\n",
    "\n",
    "#     for i in range(total_samples):\n",
    "#         i_indices = []\n",
    "#         for j in range(total_samples):\n",
    "#             if i // sequence_length == j // sequence_length:\n",
    "#                 i_indices.append(j)\n",
    "#         same_sample[i,i_indices] = 1\n",
    "    \n",
    "#     # return contrastive_matrix\n",
    "    \n",
    "#     for k in range(-window_width, window_width):\n",
    "#         window_mask += torch.diag(torch.ones((total_samples)),k)[:total_samples,:total_samples].int()\n",
    "    \n",
    "#     return same_sample * window_mask\n",
    "\n",
    "import torch\n",
    "\n",
    "def get_contrastive_matrix(batch_size, sequence_length, num_augmentations, window_size):\n",
    "    total_samples = batch_size * sequence_length * num_augmentations\n",
    "\n",
    "    # Create a matrix indicating whether samples are from the same sequence\n",
    "    \n",
    "    diag_block = torch.ones((sequence_length,sequence_length))\n",
    "    same_sequence = torch.block_diag(*((batch_size * num_augmentations) * [diag_block]))\n",
    "    \n",
    "\n",
    "    # Create a window mask\n",
    "    window_width = window_size // 2 + 1\n",
    "    window_mask = torch.diag(torch.ones((total_samples)), 0)\n",
    "\n",
    "    for k in range(1, window_width):\n",
    "        window_mask += torch.diag(torch.ones((total_samples - k)), k)\n",
    "        window_mask += torch.diag(torch.ones((total_samples - k)), -k)\n",
    "\n",
    "    # Apply the window mask\n",
    "    window_mask = window_mask[:total_samples, :total_samples].int()\n",
    "    \n",
    "\n",
    "    # Return the contrastive matrix\n",
    "    return same_sequence * window_mask\n",
    "\n",
    "print(get_contrastive_matrix(2,6,1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(torch.ones(3),1)[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('MuMRVQ': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4405aeff16a1b3990e07447ac3a41d1af66a9e297606669ae29b9b8994dfaf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
